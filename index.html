<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <link rel="icon" href="/favicon.ico">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <!-- three.js -->
  <script src="https://unpkg.com/three@0.126.0/build/three.js"></script>
  <script src="https://unpkg.com/three@0.126.0/examples/js/loaders/GLTFLoader.js"></script>

  <script type="module" src="https://unpkg.com/@google/model-viewer/dist/model-viewer.min.js"></script>
  <title>Vite App</title>
</head>
<body>
  <button onclick="activateXR()">Start Hello WebXR</button>
  <model-viewer id="modelViewer"
                src="https://modelviewer.dev/shared-assets/models/Astronaut.glb"
                ios-src="https://modelviewer.dev/shared-assets/models/Astronaut.usdz"
                alt="A 3D model of an astronaut"
                ar
                auto-rotate
                camera-controls>
  </model-viewer>

  <script>
    const modelLocations = [];
    let flower;
    let reticle;
    let session;
    let gl;
    let renderer;
    let scene;
    let camera;
    let referenceSpace;
    let viewerSpace;
    let hitTestSource;

    async function activateXR() {
      if (session && session.isImmersive) {
        session.end();
        return;
      }

      // Add a canvas element and initialize a WebGL context that is compatible with WebXR.
      const canvas = document.createElement("canvas");
      document.body.appendChild(canvas);
      gl = canvas.getContext("webgl", {xrCompatible: true});

      // Create the scene, renderer, and camera
      scene = new THREE.Scene();
      renderer = new THREE.WebGLRenderer({
        alpha: true,
        preserveDrawingBuffer: true,
        canvas: canvas,
        context: gl
      });
      renderer.autoClear = false;
      camera = new THREE.PerspectiveCamera();
      camera.matrixAutoUpdate = false;

      // Initialize a WebXR session using "immersive-ar".
      session = await navigator.xr.requestSession("immersive-ar", {requiredFeatures: ['hit-test']});
      session.updateRenderState({
        baseLayer: new XRWebGLLayer(session, gl)
      });

      // A 'local' reference space has a native origin that is located
      // near the viewer's position at the time the session was created.
      referenceSpace = await session.requestReferenceSpace('local');

      // Create another XRReferenceSpace that has the viewer as the origin.
      viewerSpace = await session.requestReferenceSpace('viewer');
      // Perform hit testing using the viewer as origin.
      hitTestSource = await session.requestHitTestSource({space: viewerSpace});

      // Load the flower model
      const loader = new THREE.GLTFLoader();
      loader.load("./src/assets/ROADWORKS_PREPARE-TO-STOP.gltf", function(gltf) {
        flower = gltf.scene;
      });

      // Load the reticle model
      loader.load("https://immersive-web.github.io/webxr-samples/media/gltf/reticle/reticle.gltf", function(gltf) {
        reticle = gltf.scene;
        reticle.visible = false;
        scene.add(reticle);

        loadSavedModels(); // Load and display saved AR models
      });

      // Add event listener for the 'select' event in the XR session
      session.addEventListener("select", handleSelectEvent);

      // Create a render loop that allows us to draw on the AR view.
      const onXRFrame = (time, frame) => {
        // Queue up the next draw request.
        session.requestAnimationFrame(onXRFrame);

        // Bind the graphics framebuffer to the baseLayer's framebuffer
        gl.bindFramebuffer(gl.FRAMEBUFFER, session.renderState.baseLayer.framebuffer);

        // Retrieve the pose of the device.
        // XRFrame.getViewerPose can return null while the session attempts to establish tracking.
        const pose = frame.getViewerPose(referenceSpace);
        if (pose) {
          // In mobile AR, we only have one view.
          const view = pose.views[0];

          const viewport = session.renderState.baseLayer.getViewport(view);
          renderer.setSize(viewport.width, viewport.height);

          // Use the view's transform matrix and projection matrix to configure the THREE.camera.
          camera.matrix.fromArray(view.transform.matrix);
          camera.projectionMatrix.fromArray(view.projectionMatrix);
          camera.updateMatrixWorld(true);

          const hitTestResults = frame.getHitTestResults(hitTestSource);
          if (hitTestResults.length > 0 && reticle) {
            const hitPose = hitTestResults[0].getPose(referenceSpace);
            reticle.visible = true;
            reticle.position.set(hitPose.transform.position.x, hitPose.transform.position.y, hitPose.transform.position.z);
            reticle.updateMatrixWorld(true);
          }

          // Render the scene with THREE.WebGLRenderer.
          renderer.render(scene, camera);
        }
      }

      session.requestAnimationFrame(onXRFrame);
    }

    function handleSelectEvent(event) {
      if (flower) {
        const clone = flower.clone();
        clone.position.copy(reticle.position);
        scene.add(clone);
        modelLocations.push({
          position: clone.position.clone(),
          rotation: clone.rotation.clone()
        });
      }
    }

    function loadSavedModels() {
      for (const location of modelLocations) {
        const clone = flower.clone();
        clone.position.copy(location.position);
        clone.rotation.copy(location.rotation);
        scene.add(clone);
      }
    }
  </script>
</body>
</html>
